{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4b3cd2f6",
   "metadata": {},
   "source": [
    "Standardization involves subtracting the mean from each feature and then dividing by the standard deviation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecad612e",
   "metadata": {},
   "source": [
    "#--Input--#\n",
    "\n",
    "X = [[1, 1], [1, 2], [1, 3], [1, 4]]\n",
    "y = [3, 4, 5, 6]\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "num_iterations = 1000\n",
    "regularization_term = 0.1\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01fda0cb",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Train a linear regression model using stochastic gradient descent (SGD) with mini-batch updates.\n",
    "\n",
    "Parameters:\n",
    "    X (array-like): Input features with shape (n_samples, n_features).\n",
    "    y (array-like): Target values with shape (n_samples,).\n",
    "    learning_rate (float, optional): The learning rate for gradient descent. Default is 0.01.\n",
    "    batch_size (int, optional): The size of the mini-batches used in training. Default is 32.\n",
    "    regularization (str or None, optional): The type of regularization used. Can be 'l1', 'l2', or None. Default is None.\n",
    "    max_iterations (int, optional): The maximum number of iterations for training. Default is 1000.\n",
    "    \n",
    "Returns:\n",
    "    sklearn.linear_model.SGDRegressor: The trained SGDRegressor model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452a903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.01715224])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1, 1], [1, 2], [1, 3], [1, 4]]\n",
    "y = [3, 4, 5, 6]\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "num_iterations = 1000\n",
    "regularization_term = 0.1\n",
    "random_state=42\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_linear_regression(X, y, learning_rate, batch_size, regularization_term, max_iterations):\n",
    "\n",
    "    # Standardize the input features for better convergence\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize the SGDRegressor with the given parameters\n",
    "    model = SGDRegressor(\n",
    "        loss = 'squared_error',\n",
    "        learning_rate = 'constant',\n",
    "        eta0 = learning_rate,\n",
    "        alpha = regularization_term,\n",
    "        max_iter = max_iterations,\n",
    "        tol = 1e-3,\n",
    "        random_state = 0\n",
    "    )\n",
    "    \n",
    "    # Train the model in mini-batches\n",
    "    n_samples = X_scaled.shape[0]\n",
    "    for iteration in range(max_iterations):\n",
    "        start_idx = 0\n",
    "        while start_idx < n_samples:\n",
    "            end_idx = start_idx + batch_size\n",
    "            X_batch = X_scaled[start_idx:end_idx]\n",
    "            y_batch = y[start_idx:end_idx]\n",
    "            model.partial_fit(X_batch, y_batch)\n",
    "            start_idx = end_idx\n",
    "    return model\n",
    "\n",
    "model = train_linear_regression(X,y,learning_rate, batch_size,regularization_term,num_iterations)\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fac72b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.82988827])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1,2],[1,3],[1,4],[1,5]]\n",
    "y = [3,4,7,8]\n",
    "n_iter = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "regularization_para = 0.1\n",
    "tolarence = 1e-5\n",
    "max_iter = 1000\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_scaled = scale.fit_transform(X)\n",
    "\n",
    "model = SGDRegressor(\n",
    "        loss = 'squared_error',\n",
    "        learning_rate = 'constant',\n",
    "        eta0 = learning_rate,\n",
    "        alpha = regularization_para,\n",
    "        max_iter = max_iter,\n",
    "        tol = tolarence,\n",
    "        random_state = 0\n",
    "        )\n",
    "\n",
    "n_sample = X_scaled.shape[0]\n",
    "\n",
    "for i in range(max_iter):\n",
    "    st_idx = 0\n",
    "    while st_idx < n_sample:\n",
    "        end_idx = st_idx + batch_size\n",
    "        X_batch = X_scaled[st_idx:end_idx]\n",
    "        y_batch = y[st_idx:end_idx]\n",
    "        model.partial_fit(X_batch,y_batch)\n",
    "        st_idx = end_idx\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3acd79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.62793646])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1,1],[1,2],[1,3],[1,4]]\n",
    "y = [3,5,6,8]\n",
    "batch_size = 2\n",
    "learning_rate = 0.01\n",
    "regularization_term = 0.1\n",
    "max_iter = 1000\n",
    "tol = 1e-3\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_scaled = scale.fit_transform(X)\n",
    "\n",
    "model = SGDRegressor(\n",
    "        loss = 'squared_error',\n",
    "        learning_rate = 'constant',\n",
    "        eta0 = learning_rate,\n",
    "        alpha = regularization_term,\n",
    "        max_iter = max_iter,\n",
    "        tol = tol,\n",
    "        random_state = 0\n",
    ")\n",
    "\n",
    "n_sample = X_scaled.shape[0]\n",
    "\n",
    "for i in range(max_iter):\n",
    "    st = 0\n",
    "    while st < n_sample:\n",
    "        end = st + batch_size\n",
    "        X_batch = X_scaled[st:end]\n",
    "        y_batch = y[st:end]\n",
    "        model.partial_fit(X_batch,y_batch)\n",
    "        st = end\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b2fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
